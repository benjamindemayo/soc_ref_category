---
title: "eyetracking_analysis_socref"
author: "Emily"
date: "11/27/2017"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(psych)
library(langcog)
library(tidyverse)
library(stringr)
library(magrittr)
```

Preliminaries.

```{r eval = FALSE}
#read in trial data.

d.trials <- data.frame()
files <- dir("trial_data")

for (f in files) {
  jf <- paste("trial_data/",f,sep="")
  jd <- read.csv(jf)
  timezero_cam = jd$camera.onset[1]
  timezero_et = jd$webcam.onset[1]
  id <- data.frame(SID = str_replace(f, ".csv", ""),
                   trial = jd$Trial.Number,
                   onset = jd$Trial.onset,
                   offset = jd$Trial.offset,
                   timezero_cam = timezero_cam,
                   timezero_et = timezero_et)
  d.trials <- bind_rows(d.trials, id)}

d.trials <- 
  d.trials %>% 
  mutate(camera_diff = timezero_et - timezero_cam) %>% 
  mutate(
    onset = (onset - camera_diff) / 1000,
    offset = (offset - camera_diff) / 1000
  )
```

```{r}
#define function to read in data.

#############################################################################
##  raw_data folder should contain et data files that end in Samples.txt   ##
#############################################################################

read.smi.idf <- function (file.name, header.rows=32, suffix.len=4) {
  
  ## DATA CLEANING 
  ## read in data
  ## comment.char gets rid of header rows, which may vary in number
  
  all.d <- read.table(file.name, sep="\t", 
                      header=T, fill=T, comment.char="#") 
  
  d <- subset(all.d, all.d$Type=="SMP")
  
  d$lx <- to.n(d$"L.POR.X..px.")
  d$rx <- to.n(d$"R.POR.X..px.")
  d$ly <- to.n(d$"L.POR.Y..px.")
  d$ry <- to.n(d$"R.POR.Y..px.")
  
  #clean up d
  d <- d[,c("Time","lx","ly","rx", "ry")]
  names(d)[1] <- "t"
  
  return(d)
}
```

```{r}
################################################################################
## PREPROCESS DATA 
## take data file with l and r, x and y, as well as stimulus, average
## eyes, do whatever preprocessing needs to be done. 
################################################################################

preprocess.data <- function(d, 
                            x.max = 1920, y.max=1080,
                            samp.rate = 30,
                            avg.eyes=TRUE) {
  
  ## drop the .jpg from the stimulus
  ##d$stimulus <- str_replace(d$stimulus,pattern=".jpg",replacement="")
  
  # remove bad looks before averaging the eyes
  d %<>%
    mutate(rx = ifelse(rx < 1 | rx > 1919, NA, rx),
           lx = ifelse(lx < 1 | lx > 1919, NA, lx),
           ry = ifelse(ry < 1 | ry > 1079, NA, ry),
           ly = ifelse(ly < 1 | ly > 1079, NA, ly))
  
  ## average the eyes
  if (avg.eyes) {
    # if we have both eyes, then average to the nearest pixel
    # if one of the eyes is missing, then just use the other eye's coordinate
    d %<>%
      mutate(x = ifelse(!is.na(rx) & !is.na(lx), (lx+rx) / 2,
                        ifelse(is.na(rx) & !is.na(lx), lx, 
                               ifelse(is.na(lx) & !is.na(rx), rx, 
                                      NA))),
             y = ifelse(!is.na(ry) & !is.na(ly), (ly+ry) / 2,
                        ifelse(is.na(ry), ly, 
                               ifelse(is.na(ly), ry, 
                                      NA)))
             )
    
    # remove the l/r eye variable names
    d <- d[, !(names(d) %in% c("lx","rx","ly","ry"))]
  }
  
  ## clip off out of range numbers
  d$x[d$x < 0 | d$x > x.max] <- NA
  d$y[d$y < 0 | d$y > y.max] <- NA
  
  ## convert the time into seconds
  d$t <- round((d$t - d$t[1])/(1000000), 3)
 
  ## ms.increment <- c(0, diff(d$t))
  
  ## add a column of times for each video segment
  ## note this code makes me somewhat ashamed; it's slow and it abuses the R namespace
  ## because it's basically a for loop. but I don't know how to fix it. -mcf
 
   # stim.change <- c(diff(as.numeric(factor(d$stimulus))) != 0,0)
  # dt <- c(diff(d$t),0)
  # t <- 0
  # d$t.stim <- mapply(function (x,y) { 
  #   if(x==TRUE) { # if stimulus changes
  #     t <<- 0 # reset counter
  #     return(t)
  #   } else { # if stimulus is the same
  #     t <<- t + y # increment counter
  #     return(t)
  #   }},stim.change,dt)
  
  ## round to the nearest sample
  # d$t.stim <- round(d$t.stim*samp.rate)/samp.rate
  
  ## y flip (so origin is cartesian, not matrix (bottom left, instead of top left)
  d$y <- y.max - d$y
  
  ## finished
  return (d)
}
```

Read in experiment data and preprocess.
```{r}
raw.data.path <- "raw_data/"
processed.data.path <- "processed_data/"

## LOOP TO READ IN FILES
all.data <- data.frame()
files <- dir(raw.data.path,pattern="*.txt")

to.n <- function(x) {as.numeric(as.character(x))}
sem <- function(x) {sd(x) / sqrt(length(x))}

for (file.name in files) {
  ## print file name, so if loop breaks, we know where
  print(file.name)
  
  ## these are the two functions that are most meaningful
  d <- read.smi.idf(paste(raw.data.path,file.name,sep=""))
  d <- preprocess.data(d, x.max = 1920, y.max= 1080, samp.rate = 30, avg.eyes = T) 
  
  d$sid <- str_replace(file.name, "-eye_data Samples.txt", "")
  
  ## now here's where data get bound togetherq
  all.data <- bind_rows(all.data, d)
}

write_csv(all.data, path=paste0(processed.data.path, "socref_cat_data.csv"))
```

```{r}
ggplot(d, aes(x = x, y = y)) +
 geom_point(alpha = 0.3)# +
  #lims(x = c(0, 1920), y = c(0,1080))
```

```{r}
d %>% 
  ggplot(aes(x = t, y = y)) +
  geom_vline(data = d.trials, aes(xintercept = onset), color = "blue") +
  geom_vline(data = d.trials, aes(xintercept = offset), color = "red") +
  coord_cartesian(xlim = c(105, 160))
```


```{r}
#merge ET data with trial info

d$trial[d$t>= d.trials$onset[d.trials$trial == "1"] && d$t<= d.trials$offset[d.trials$trial == "1"]] <- 1



```


